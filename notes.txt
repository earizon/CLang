●  Apropos:
- Visit next Web site for a great experience:
  https://earizon.github.io/txt_world_domination/viewer.html?payload=../CLang/notes.txt

- If you want to contribute to great gistory of this document you can
  take the next flight to:
@[https://www.github.com/earizon/CLang]
  Your commits and pull-request will be immortalized in the Pantheon of the Unicode Gods.


Misserable collection of unordered C/C++ notes:

• GCC summary: [[{gcc.101,01_PM.TODO]] #[gcc_summary]
See gcc related tldr:
@[https://github.com/tldr-pages/tldr/tree/master/pages/common]
@[https://github.com/tldr-pages/tldr/blob/master/pages/common/clang.md]
@[https://clang.llvm.org/docs/ClangCommandLineReference.html]


  $ gcc ${source1.c} ${source2.c} \   ← Compile N source files,
      -o ${executable}                   ← to exec
      -Wall                              ← Allow warnings
      -Og                                ← debug symbols to STDOUT
      -I${header_path}                   ← add headers paths
      -L${library_path}                  ← add library paths
      -l${library_name}                  ← add library
   NOTE: Use c99 (vs gcc) + default options to switch to ISO C standard.
   NOTE: Most commands are similar in gcc and clang LLVM compiler.

  $ gcc -S ${source.c}                   ← Compile src to Assembler

  $ gcc -c ${source.c}                   ← Compile src, do NOT link

  $ clang -S -emit-llvm ${file.c} \      ← Compile src to LLVM Intermediate Rep.
$     -o ${file.ll}
[[}]]

● Cscope  [[{]]
  - interactively examine a C "source" program files:
    - C    .c/.h
    - lex  .l
    - yacc .y
    (by default in the current  directory and standard include directories)

  - cscope.out:
    - built on first run.
    - rebuilt on file-source changes.
    - data for unchanged files is cached.
    symbol cross-reference database index for:
    - functions
    - function calls
    - macros
    - variables
    - preprocessor symbols

man cscope

cscope $OPTIONS file1 file2 ...

-b  Build the cross-reference only.
-C  Ignore letter case when searching.
-c  Use only ASCII characters in the cross-reference file,
  that is, do not compress the data.
-d  Do not update the cross-reference.
-e  Suppress the <Ctrl>-e command prompt between files.
-F${symfile} Read symbol reference lines from symfile.
  (A symbol reference file is created by >
  and >>, and can also be read using the <
  command, described under ``Issuing Subsequent Requests'', below.)
-f${reffile} Use reffile instead of "cscope.out".
-I${incdir} Use cwd -> $INCDIR -> /usr/include for headers.
-i${namefile} Use $namefile instead of cscope.files for list of
  source files.
-k  ``Kernel Mode'', turns /usr/include, not used by kernel.

-L  Do a single search with line-oriented output when used
  with the -num pattern option.

-l  Line-oriented interface (see ``Line-Oriented Interface'' below).

-[0-9]pattern
  Go to input field num (counting from 0) and find pattern.

-P${path} Prepend path to relative file names in pre-built cscope.out
  (only valid with the -d option).

-p$n Display last n file path components instead default (1).
  0 => DO not display the file name at all.

-q  Enable fast symbol lookup via inverted index.
  'cscope.in.out' and 'cscope.po.out' will be created.
  Provie performance improvements in LARGE PROJECTS.

-R  Recurse subdirectories during search for source files.

-s$dir Use also $dir for source files.
  (ignored if source files are provided in cli)

-T Use only first eight chars to match against C symbols.
   (regex with special chars other than '.' will fail.

-U  Check file time stamps and update in cscope.out to last update.

-u  Unconditionally build (assume changes in all files).

-v  verbose output

-X  Remove cscope.out and inverted indexes.

- Navigating into search results:
  +  Display next set of matching lines.
  -  Display previous set of matching lines.
  ^e Edit displayed files in order.
  >  Write  displayed list-of-lines to file.
  >> Append displayed list-of-lines to file.
  <  Read lines from file that is in symbol
     reference format (created by > or >>),
     just like the -F option.
  ^  Filter all lines through a shell command,
     display resulting lines.
  |  Pipe all lines to shell command
     display them without changing them.

  ^n  Move to next input field. (or just "<Return>")
  ^f  Move to next input field and search pattern.
  ^p  Move to prev.input field.
  ^b  Move to prev.input field and search pattern.
  ^y  Search with the last text typed.
  ^c  Toggle case-match.
  ^r  Rebuild cross-reference.
  !   Start interactive shell (^d: go back to cscope).
  ^l  Redraw the screen.
  ?   help about cscope commands.
  ^d  Exit cscope.
[[}]]

● Seastar: async lib replacing threads [[{async/reactive,performance,scalability,qa.UX,01_PM.TODO]]
@[http://seastar.io]
@[https://github.com/scylladb/seastar]
- shared memory, mapped files, and other classic Linux programming.
- C++ framework for high-performance server applications on modern hardware.
- Used, among others, by Scylla, high-performance NoSQL database alternative
  to Apache Cassandra.
- Runs on Linux or OSv.

- Shared-nothing design: shards all requests onto individual cores.
- High-performance networking: Choice network stack:         [[{i/o.network]]
  - conventional Linux networking for ease of development.
  - DPDK for fast user-space networking on Linux.
  - native networking on OSv.                                [[}]]

- Futures and promises: "new" model for concurrent applications offering
  both high performance and comprehensible, testable high-quality code.

- Message passing: Share info. between CPU cores without time-consuming locking [[{thread.lock}]]
[[}]]

● JAM build tool  [[{qa.UX,01_PM.low_code,01_PM.TODO]]
@[http://www.perforce.com/jam/jam.html]
makes building simple things simple and building complicated things manageable.

Jam understands C/C++ dependencies, there is no need to declare header or object files.

Jamfile                             Makefile
Main proga : data.c main.c io.c ;   proga: data.o main.o io.o
                                      cc data.o main.o io.o -o proga
                                    data.o: data.c data.h
                                      cc -c data.c

                                    main.o: data.h io.h main.c
                                      cc -c main.c

                                    io.o: io.h io.c
                                      cc -c io.c
[[}]]

● Efficient string copying & concatenation: [[{101.strings]]
@[https://developers.redhat.com/blog/2019/08/12/efficient-string-copying-and-concatenation-in-c/]
[[}]]

● ZZ transpiler (to ANSI-C) [[{qa.formal_proofs.zz,]]
@[https://www.infoq.com/news/2020/02/zz-formal-verified-c-dialect/]


ZetZ, or ZZ for short, is a Rust-inspired C dialect that is able to formally
verify your code by executing it symbolically at compile time in a virtual
machine.
- targeted to software running "close to hardware", can also be
  used to build cross-platform, ANSI-C compliant libraries.
- In contrast to how many modern languages approach safety, ZZ does not
  preclude or limit features that are deemed "unsafe", such as raw pointer
  access. Rather, it uses static single assignment form (SSA) to prove your
  code is undefined behaviour-free at compile time in a SMT prover such as
  yices2 or z3.
[[}]]

● What's new: [[{01_PM.NEW]]
  C++20 Is Now Final, C++23 At Starting Blocks
@[https://www.infoq.com/news/2020/09/cpp-20-final/]

  GCC 10 C++ features
@[https://developers.redhat.com/blog/2020/09/24/new-c-features-in-gcc-10/]

- ISO C: July 2019
@[https://developers.redhat.com/blog/2019/09/03/report-from-july-2019-iso-c-meeting-core-language/]


- Changes in the C++ ABI between RHEL 7 and RHEL 8 are due to
  introducing new versions of std::string and std::list in the C++
  standard library. For details about the changes to the std::string
  ABI, see Jason Merril’s article, GCC5 and the C++11 ABI. The
  changes to the C++ ABI apply to all language modes, so it doesn’t
  matter whether you are compiling for -std=c++11 or any other -std
  option.
  https://developers.redhat.com/blog/2015/02/05/gcc5-and-the-c11-abi/
[[}]]

● Simplified Wrapper and interface Generator [[{]]
  http://www.swig.org/
(used by NumPy for example: https://docs.scipy.org/doc/numpy/reference/swig.interface-file.html)
 - SDK connecting  C and C++ with a variety of high-level languages.
 SWIG is
used with different types of target languages including common
scripting languages such as Javascript, Perl, PHP, Python, Tcl and
Ruby. The list of supported languages also includes non-scripting
languages such as C#, D, Go language, Java including Android, Lua,
OCaml, Octave, Scilab and R. Also several interpreted and compiled
Scheme implementations (Guile, MzScheme/Racket) are supported. SWIG
is most commonly used to create high-level interpreted or compiled
programming environments, user interfaces, and as a tool for testing
and prototyping C/C++ software. SWIG is typically used to parse C/C++
interfaces and generate the 'glue code' required for the above target
languages to call into the C/C++ code. SWIG can also export its parse
tree in the form of XML. SWIG is free software and the code that SWIG
generates is compatible with both commercial and non-commercial
projects.
[[}]]


● Google Propeller: [[{01_PM.TODO]]
@[https://www.infoq.com/news/2020/03/google-propeller-llvm-optmizer/]
[[}]]

● Subset C Compiler [[{01_PM.TODO]]
https://github.com/sudheesh001/SubsetC
Subset C Compiler built to handle basic compiler functionality with a
language thats similar to C. It generates intermediate code and
possible code generation.
[[}]]

● Static analysis in GCC 10: [[{qa.code]]
https://developers.redhat.com/blog/2020/03/26/static-analysis-in-gcc-10/

By David Malcolm March 26, 2020

I work at Red Hat on GCC, the GNU Compiler Collection. For the next
major release of GCC, GCC 10, I’ve been implementing a new
-fanalyzer option: A static analysis pass to identify various
problems at compile-time, rather than at runtime.

My thinking here is that it’s best to catch problems as early as
possible as the code is written, using the compiler the code is
written in as part of the compile-edit-debug cycle, rather than
having static analysis as an extra tool “on the side” (perhaps
proprietary). Hence, it seems worthwhile to have a static analyzer
built into the compiler that can see exactly the same code as the
compiler sees—because it is the compiler.

This issue is, of course, a huge problem to tackle. For this release,
I’ve focused on the kinds of problems seen in C code—and, in
particular double-free bugs—but with a view toward creating a
framework that we can expand on in subsequent releases (when we can
add more checks and support languages other than C).

My hope is that the analyzer provides a decent amount of extra
checking while not being too expensive. I’ve aimed for -fanalyzer
to “merely” double the compile time as a reasonable trade-off for
the extra checks. I haven’t succeeded yet, as you’ll see below,
but I’m working on it.

https://developers.redhat.com/blog/2021/01/28/static-analysis-updates-in-gcc-11?sc_cid=7013a0000026SuaAAE#
GCC 10 implementation of -fanalyzer added 15 warnings:
    Warnings relating to memory management:
        -Wanalyzer-double-free
        -Wanalyzer-use-after-free
        -Wanalyzer-free-of-non-heap
        -Wanalyzer-malloc-leak
    Warnings relating to missing error-checking or misusing NULL pointers:
        -Wanalyzer-possible-null-argument
        -Wanalyzer-possible-null-dereference
        -Wanalyzer-null-argument
        -Wanalyzer-null-dereference
    Warnings relating to stdio streams:
        -Wanalyzer-double-fclose
        -Wanalyzer-file-leak
    Warnings relating to use-after-return from stack frames:
        -Wanalyzer-stale-setjmp-buffer
        -Wanalyzer-use-of-pointer-in-stale-stack-frame
    Unsafe call warning:
        -Wanalyzer-unsafe-call-within-signal-handler
    Proof-of-concept warnings:
        -Wanalyzer-tainted-array-index
        -Wanalyzer-exposure-through-output-file

For GCC 11, I've added four new warnings:

    -Wanalyzer-write-to-const
    -Wanalyzer-write-to-string-literal
    -Wanalyzer-shift-count-negative
    -Wanalyzer-shift-count-overflow

I am still developing -fanalyzer only for C in GCC 11. I added
partial support for C++'s new and deleteBut there are enough missing
features that it's not yet worth using on real C++ code. I plan to
make the analyzer robust and scalable for C code in GCC 11 and defer
C++ support to GCC 12.

GCC 11 will be in Fedora 34, which should also be out in the spring
of 2021. For simple code examples, you can play around with the new
GCC online at godbolt.org. Select your GCC "trunk" and add -fanalyzer
to the compiler options. Have fun!
[[}]]

● Google TCMalloc: [[{01_PM.TODO]]
TCMalloc, Google's Customized Memory Allocator for C and C++, Now Open Source
https://www.infoq.com/news/2020/02/google-tc-malloc-open-source/
[[}]]


● C/C++ aliasing joys/perils: [[{01_PM.TODO]]
101 https://developers.redhat.com/blog/2020/06/02/the-joys-and-perils-of-c-and-c-aliasing-part-1/
The joys and perils of C and C++ aliasing, Part 1
[[}]]


● Radare Reverse-Engineering [[{cli,reverse-engineering,forensics,security,binary-analysis,malware-analysis,disassembler,01_PM.TODO]]
@[www.radare.org/]
@[https://github.com/radareorg/radare2]
UNIX-like reverse engineering framework and command-line toolset
[[}]]


● Conan Package Manager: [[{qa.UX,01_PM.TODO]]
https://conan.io/
Conan, the C/C++ Package Manager
The open source, decentralized and multi-platform packagemanager to
create and share all your native binaries.
[[}]]

● CXX Safe Interoperability Rust:[[{rust,interoperability,01_PM.TODO]]
https://www.infoq.com/news/2020/12/cpp-rust-interop-cxx/
[[}]]

● CoreDumper:[[{troubleshooting.debugger,01_PM.TODO]]
@[https://github.com/AmadeusITGroup/CoreDumper]
Clone of https://code.google.com/p/google-coredumper/ with enhancements by Amadeus

The coredumper library can be compiled into applications to create
core dumps of the running program, without having to terminate
them. It supports both single- and multi-threaded core dumps, even if
the kernel does not have native support for multi-threaded core files.

This library is primarily intended to simplify debugging of
long-running services. It is often inacceptable to suspend production
services by attaching a debugger, nor is it possible to crash the
service in order to generate a core file.
[[}]]

● Cheerp WebAssembly Compiler: [[{webassembly,01_PM.TODO]]
@[https://www.leaningtech.com/pages/cheerp.html]
[[}]]

● Debugger, C, WAsm [[{]]
https://www.infoq.com/news/2021/01/chrome-extension-debug-wasm-c/
[[}]]

● Tips for writing portable assembler with GNU Assembler (GAS) [[{]]
https://developers.redhat.com/blog/2021/02/26/tips-for-writing-portable-assembler-with-gnu-assembler-gas/
[[}]]

● interactive C++ for data science: [[{]]
https://blog.llvm.org/posts/2020-12-21-interactive-cpp-for-data-science/
[[}]]

● https://makefiletutorial.com/  [[{101.make]]
  https://github.com/theicfire/makefiletutorial
[[}]]


● Performance boost tips in 'ag' search [[{performance,strings,regex,01_PM.TODO]]
https://github.com/ggreer/the_silver_searcher
How is it so fast?
- Ag uses Pthreads to take advantage of multiple CPU cores and search files in parallel.
- Files are mmap()ed instead of read into a buffer.
- Literal string searching uses Boyer-Moore strstr.
- Regex searching uses PCRE's JIT compiler (if Ag is built with PCRE >=8.21).
- Ag calls pcre_study() before executing the same regex on every file.
- Instead of calling fnmatch() on every pattern in your ignore files,
  non-regex patterns are loaded into arrays and binary searched.
[[}]]

● astyle [[{qa]]
https://github.com/tldr-pages/tldr/blob/master/pages/common/astyle.mode

Source code indenter, formatter, and beautifier for the C, C++, C#
and Java programming languages. Upon running, a copy of the original
file is created with an ".orig" appended to the original file name.
More information: http://astyle.sourceforge.net/.
[[}]]

● cppcheck  [[{]]
@[https://github.com/tldr-pages/tldr/blob/master/pages/common/cppcheck.md] @ma
Static analysis tool for C/C++ code.
it focuses on the types of bugs that compilers normally do not detect

cppcheck

    A static analysis tool for C/C++ code. Instead of syntax errors, it focuses on the types of bugs that compilers normally do not detect. More information: http://cppcheck.sourceforge.net.

    Recursively check the current directory, showing progress on the screen and logging error messages to a file:

cppcheck . 2> cppcheck.log

    Recursively check a given directory, and don't print progress messages:

cppcheck --quiet ${path/to/directory}

    Check a given file, specifying which tests to perform (by default only errors are shown):

cppcheck --enable=${error|warning|style|performance|portability|information|all} ${path/to/file.cpp}

    List available tests:

cppcheck --errorlist

    Check a given file, ignoring specific tests:

cppcheck --suppress=${test_id1} --suppress=${test_id2} ${path/to/file.cpp}

    Check the current directory, providing paths for include files located outside it (e.g. external libraries):

cppcheck -I ${include/directory_1} -I ${include/directory_2} .

    Check a Microsoft Visual Studio project (*.vcxproj) or solution (*.sln):

cppcheck --project=${path/to/project.sln}
[[}]]


https://github.com/tldr-pages/tldr/blob/master/pages/common/cppclean.md
Find unused code in C++ projects. More information: https://github.com/myint/cppclean.
######################
https://github.com/tldr-pages/tldr/blob/master/pages/common/ctags.md @ma
####################
https://github.com/tldr-pages/tldr/blob/master/pages/common/doxygen.md  101
####################
See make examples:
https://github.com/tldr-pages/tldr/blob/master/pages/common/entr.md
####################
https://github.com/tldr-pages/tldr/blob/master/pages/common/gdb.md @ma  101
https://interrupt.memfault.com/blog/advanced-gdb#gdb-visual-interfaces

Set breakpoint: (http://www.delorie.com/gnu/docs/gdb/gdb_29.html)
 $ break ""function_name""   ˂- break at function
 $ break filename:linenum  ˂- break at filename:line
Remove breakpoint:
 $ clear ""function""|""line number""|...
List breakpoints:
 $ info breakpoints
Save breakpoints:
 $ save breakpoints ˂filename˃
Restore breakpoints:
1.- Add first the line ""set breakpoint pending on to ˂filename˃"".
2.- $ source ˂filename˃
""Moving"":
 n -˃ Next (do not enter function)
 s -˃ Step (enter function)
 finish -˃ Step ""out"" of the function
---------------------
"ref: http://stackoverflow.com/questions/1354637/watchpoint-in-gdb
""command"" can be used to set a list of GDB commands to execute whenever a breakpoint is hit. Very useful:

Ex1: ""Suppose that I have a function format that is called by a lot of other functions. I want to break on it,
but only after function do_step_3 has been called.""

break do_step_3
commands
  break format
  continue
end
---------------------
"Conditional watch:
 $ watch my_var if my_var ˃ 3
---------------------
"You can set a watchpoint that does not go out of scope by setting it to the memory address.

(gdb) p &var1
$1 = (int *) 0x41523c0
(gdb) watch  (int  )0x41523c0
Hardware watchpoint 1:  (int  )0x41523c0
---------------------


(gdb) help breakpoints. List of commands:
awatch -- Set a watchpoint for an expression · · · · · · · · |break -- Set breakpoint at specified line or function
break-range -- Set a breakpoint for an address range · · · · |catch -- Set catchpoints to catch events
catch assert -- Catch failed Ada assertions· · · · · · · · · |catch catch -- Catch an exception
catch exception -- Catch Ada exceptions· · · · · · · · · · · |catch exec -- Catch calls to exec
catch fork -- Catch calls to fork· · · · · · · · · · · · · · |catch syscall -- Catch system calls by their names and/or numbers
catch throw -- Catch an exception· · · · · · · · · · · · · · |catch vfork -- Catch calls to vfork
clear -- Clear breakpoint at specified line or function· · · |commands -- Set commands to be executed when a breakpoint is hit
condition -- Specify breakpoint number N to break only if COND is true
delete -- Delete some breakpoints or auto-display expressions
delete bookmark -- Delete a bookmark from the bookmark list ·|delete breakpoints -- Delete some breakpoints or auto-display expressions
delete checkpoint -- Delete a checkpoint (experimental) · · ·|delete display -- Cancel some expressions to be displayed when program stops
delete mem -- Delete memory region· · · · · · · · · · · · · ·|delete tracepoints -- Delete specified tracepoints
delete tvariable -- Delete one or more trace state variables·|disable -- Disable some breakpoints
disable breakpoints -- Disable some breakpoints · · · · · · ·|disable display -- Disable some expressions to be displayed when program stops
disable mem -- Disable memory region· · · · · · · · · · · · ·|disable pretty-printer -- GDB command to disable the specified pretty-printer
disable tracepoints -- Disable specified tracepoints· · · · ·|enable -- Enable some breakpoints
enable breakpoints -- Enable some breakpoints · · · · · · · ·|enable breakpoints delete -- Enable breakpoints and delete when hit
enable breakpoints once -- Enable breakpoints for one hit · ·|enable delete -- Enable breakpoints and delete when hit
enable display -- Enable some expressions to be displayed when program stops
enable mem -- Enable memory region· · · · · · · · · · · · · ·|enable once -- Enable breakpoints for one hit
enable pretty-printer -- GDB command to enable the specified |pretty-printer
enable tracepoints -- Enable specified tracepoints· · · · · ·|ftrace -- Set a fast tracepoint at specified line or function
hbreak -- Set a hardware assisted breakpoint· · · · · · · · ·|ignore -- Set ignore-count of breakpoint number N to COUNT
rbreak -- Set a breakpoint for all functions matching REGEXP·|rwatch -- Set a read watchpoint for an expression
save -- Save breakpoint definitions as a script · · · · · · ·|save breakpoints -- Save current breakpoint definitions as a script
save gdb-index -- Save a gdb-index file · · · · · · · · · · ·|save tracepoints -- Save current tracepoint definitions as a script
skip -- Ignore a function while stepping· · · · · · · · · · ·|skip delete -- Delete skip entries
skip disable -- Disable skip entries· · · · · · · · · · · · ·|skip enable -- Enable skip entries
skip file -- Ignore a file while stepping · · · · · · · · · ·|skip function -- Ignore a function while stepping
strace -- Set a static tracepoint at specified line · · · · ·|tbreak -- Set a temporary breakpoint
tcatch -- Set temporary catchpoints to catch events · · · · ·|tcatch assert -- Catch failed Ada assertions
tcatch catch -- Catch an exception· · · · · · · · · · · · · ·|tcatch exception -- Catch Ada exceptions
tcatch exec -- Catch calls to exec· · · · · · · · · · · · · ·|tcatch fork -- Catch calls to fork
tcatch syscall -- Catch system calls by their names and/or numbers
tcatch throw -- Catch an exception· · · · · · · · · · · · · ·|tcatch vfork -- Catch calls to vfork
thbreak -- Set a temporary hardware assisted breakpoint · · ·|trace -- Set a tracepoint at specified line or function
watch -- Set a watchpoint for an expression

######################
Compiles resource files (e.g. images) into a binary resource bundle.
These may be linked into GTK applications using the GResource API.
https://github.com/tldr-pages/tldr/blob/master/pages/common/glib-compile-resources.md
######################
Indent
Change the appearance of a C/C++ program by inserting or deleting
whitespace. More information: https://www.gnu.org/software/indent/.
https://github.com/tldr-pages/tldr/blob/master/pages/common/indent.md
#########################
- The LLVM Low-Level Debugger. More information: https://lldb.llvm.org.
https://github.com/tldr-pages/tldr/blob/master/pages/common/lldb.md

##########################
LORDER(1)            BSD General Commands Manual                  LORDER(1)

NAME
     lorder — list dependencies for object files  101

SYNOPSIS
     lorder file ...

DESCRIPTION
     The lorder utility uses nm(1) to determine interdependencies in the list of object files and library archives
     specified on the command line.  The lorder utility outputs a list of file names where the first file contains
     a symbol which is defined by the second file.

     The output is normally used with tsort(1) when a library is created to determine the optimum ordering of the
     object modules so that all references may be resolved in a single pass of the loader.

     When linking static binaries, lorder and tsort(1) can be used to properly order library archives automati‐
     cally.

ENVIRONMENT
     NM      Path to the nm(1) binary, defaults to “nm”.

     NMFLAGS
             Flags to pass to nm(1).

EXAMPLES
           ar cr library.a `lorder ${OBJS} | tsort`
           cc -o foo ${OBJS} `lorder ${STATIC_LIBS} | tsort`

SEE ALSO
     ar(1), ld(1), nm(1), ranlib(1), tsort(1) 101
##########################
https://github.com/tldr-pages/tldr/blob/master/pages/common/make.md @ma
##########################
https://github.com/tldr-pages/tldr/blob/master/pages/common/msbuild.md
    The Microsoft build tool for Visual Studio project solutions.
More information: https://docs.microsoft.com/visualstudio/msbuild.
##########################
https://github.com/tldr-pages/tldr/blob/master/pages/common/nasm.md
The "old?" Netwide Assembler, a portable 80x86 assembler. More information: https://nasm.us.
See also yasm rewrite of nasm under BSD license.

SASM: Simple ide for NASM, GAS and FASM assembly families:
https://dman95.github.io/SASM/english.html
#########################
https://github.com/tldr-pages/tldr/blob/master/pages/common/objdump.md  101
- View information about object files.
########################
https://github.com/tldr-pages/tldr/blob/master/pages/common/opt.md
A tool that takes LLVM source files and runs specified
optimizations and/or analyses on them. More information:
https://llvm.org/docs/CommandGuide/opt.html.

● Autotools  [[{]]
http://www.lrde.epita.fr/~adl/autotools.html"
Autotools vs SCons vs CMake:
@[http://stackoverflow.com/questions/4071880/autotools-vs-cmake-vs-scons]
www-alt.gsi.de/documents/DOC-2007-Sep-17-1.pdf

http://fr.wikipedia.org/wiki/Autotools
"Ref: http://www-igm.univ-mlv.fr/~dr/XPOSE/Breugnot/

  Makefile.am ───┬───→ Automake ───→ Makefile.in ───┐
                 │                                  │
       ┌─────────┘                                  │
       v                                            v
  Configure.in ─────→ Autoconf ──────────────────˃ Configure ──˃ Makefile


  Configure.in ─────────────˃ Autoconf ───˃ Configure
                                ^
  Aclocal ────→ Aclocal.mp4 ────┘


  (Makefile.am, Configure.in) - -˃ Automake - -˃ Makefile.in


  (Aclocal) -˃ Aclocal.mp4


  (Configure.in, Aclocal.mp4) -˃ Autoconf -˃ Configure


  (Makefile.in) -˃ Configure -˃ Makefile

  (Configure.in, Accconfig.h) -˃ Autoheader -˃ Config.h.in -˃ Configure


  Configure.in: Options we want to test in our system (library dependencies,...)
  Makefile.am : Tells how the code must be build. It has a serie of Automake
                macro definitions with the form:
                variable = value
  Autoheader  : Helps to sync header (include ...) dependencies."

  Autotools Mythbuster: https://autotools.io/index.html

    When                Command     Actions
  -------------------------------------------------------------------------------------
    Start of project    autoscan    Creates template file for Configure.in
                                    Writes Makefile.am (program structure)

                        aclocal     To install extra utility tools for automake

                        autoheader  To determine pre-processor variables to be defined,
                                    and saving them to 'config.h.in' file
  -------------------------------------------------------------------------------------
    at start or when    autoconf    Creates 'configure' from 'Configure.in'
    'configure.in'
    is modified
  -------------------------------------------------------------------------------------
    at start or when    automake    Creates 'Makefile.in' from 'Makefile.am'
    'makefile.in' is
    lost
  -------------------------------------------------------------------------------------
    To change config.   configure   Creates 'Makefile' and 'config.h' depending on
                                    compilation options choosen.
  -------------------------------------------------------------------------------------
    To compile sources  make        Compile les sources ou met à jour les binaires
    to executable
  -------------------------------------------------------------------------------------
[[}]]

● Valgrind  [[{Valgrind,debugging,profiling,qa,01_PM.TODO]]  101
@[http://valgrind.org/docs/manual/manual.html]
http://valgrind.org/docs/manual/cg-manual.html
- Memcheck   : memory error detector.               [debugging]

- Cachegrind : cache and branch-prediction profiler [profiling]
- Callgrind  : call-graph generating cache profiler.
               some overlap with Cachegrind but also gathers
               extra information.

- Helgrind   : thread error detector, making multi-threaded programs [locks]
               more correct.
 (DRD is similar to Helgrind but uses different analysis techniques
  and so may find different problems).

- Massif     : heap profiler, to make programs consume less memory.
- DHAT       : different kind of heap profiler helping to understand issues
               of block lifetimes, block utilisation, and layout inefficiencies.
- SGcheck    : experimental tool to detect overruns of stack and global arrays.
               (complementary to that of Memcheck)

- BBV        : experimental SimPoint basic block vector generator, useful to people
               doing computer architecture research and development.

"Profiling C/C++: (Stackoverflow)
You can use valgrind with the following options
valgrind --tool=callgrind ./(Your binary)
It will generate a file called callgrind.out.x. You can then use
kcachegrind tool to read this file. It will give you a graphical
analysis of things with results like which lines cost how much.
        ________
"
"Answer to run valgrind --tool=callgrind is not quite
complete without some options. We usually do not want to profile 10
minutes of slow startup time under valgrind and want to profile our
program when it is doing some task.

So this is what I recommend. Run program first:

valgrind --tool=callgrind --dump-instr=yes -v --instr-atstart=no ./binary ˃ tmp

Now when it works and we want to start profiling we should run in another window:

callgrind_control -i on

This turns profiling on. To turn it off and stop whole task we might use:

callgrind_control -k

Now we have some files named callgrind.out.* in current directory. To see profiling results use:

kcachegrind callgrind.out.*

I recommend in next window to click on ""Self"" column header,
otherwise it shows that ""main()"" is most time consuming task. ""Self""
shows how much each function itself took time, not together with
dependents.
[[}]]

● PROFILING: [[{]]
"1999 : LTT, 2005 : LTTng, 2005 : Dtrace,  2008 : Ftrace, 2009 : Perf, 2012 : LTTng 2.0
https://lttng.org/lttng2.0
http://lttng.org/files/papers/presentations/lttng20tracingforeveryone.pdf
src: http://lttng.org/files/papers/presentations/lttng20tracingforeveryone.pdf
(create, enable, start, stop, view, destroy)
# lttng create
# lttng enable-event -k -a
# lttng enable-event -u -a
# lttng start
# lttng stop
# lttng view
# lttng destroy

------------------------------------------------------------------------
gprof
http://www.pixelbeat.org/programming/profiling/
How to use gprof with multi-threaded apps: http://sam.zoy.org/writings/programming/gprof.html
------------------------------------------------------------
http://stackoverflow.com/questions/375913/what-can-i-use-to-profile-c-code-in-linux
http://stackoverflow.com/questions/2497211/how-to-profile-multi-threaded-c-application-on-linux
http://stackoverflow.com/questions/375913/what-can-i-use-to-profile-c-code-in-linux/378024#378024
-------------------------------------------------------------------
PROFILING:
""Have a look at oprofile. The profiling overhead of this tool is negligible and it supports
multithreaded applications---as long as you don't want to profile mutex
contention (which is a very important part of profiling multithreaded
applications)""
--------------------------------------------
"http://poormansprofiler.org/                                                          [[{qa.UX]]
""Sampling tools like oprofile or dtrace's profile provider don't really provide
methods to see what [multithreaded] programs are blocking on - only where they spend
CPU time.
Though there exist advanced techniques (such as systemtap and dtrace call level probes),
it is overkill to build upon that. Poor man doesn't have time. Poor man needs food. "" [[}]]

● SystemTAP, PROFILING:                        [[{]]
  "In order to aid in debugging and monitoring internal behavior, the
  GNU C Library exposes nearly-zero-overhead SystemTap probes marked
  with the libc provider.  These probes are not part of the GNU C
  Library stable ABI, and they are subject to change or removal across
  releases. Our only promise with regard to them is that, if we find a
  need to remove or modify the arguments of a probe, the modified probe
  will have a different name, so that program monitors relying on the
  old probe will not get unexpected arguments.  [[}]]

● perf                                 [[{]
"Newer kernels (e.g. the latest Ubuntu kernels) come with the new
'perf' tools (apt-get install linux-tools) aka perf_events
http://web.archive.org/web/20111105130616/http://blog.bepointbe.be/index.php/2008/10/19/30-a-bit-of-plasma-profiling

These come with classic sampling profilers (man-page) as well as the awesome timechart!

The important thing is that these tools can be system profiling
 and not just process profiling - they can show the interaction between
threads, processes and the kernel and let you understand the scheduling
and IO dependencies between processes.  [[}]]

● oprofile  is good because it makes it much easier than gprof
  to profile multiple programs at once. You also can run it
  on your release build (if it has symbols), instead of having to build
  a special profiling build.
  If you don't care about taking a massive performance hit (50x),
  valgrind (cachegrind) is good.
------------------------------------------
You can use callgrind. Together with KCacheGrind, it gives a pretty
nice profiler. Besides that, Intel VTune is free for educational use
on Linux. It is probably the best profiler out there. If you have an
AMD CPU, use AMD Codeanalyst (succeeded by AMD’s CodeXL), which is
also available for Linux; this one is only decent, but free.

  I would use Valgrind and Callgrind as a base for my profiling tool suite.
What is important to know is that Valgrind is basically a Virtual Machine:
  (wikipedia) Valgrind is in essence a virtual
  machine using just-in-time (JIT)  compilation techniques, including
  dynamic recompilation. Nothing from  the original program ever gets run
  directly on the host processor.  Instead, Valgrind first translates the
  program into a temporary, simpler form  called Intermediate Representation
  (IR), which is a processor-neutral,  SSA-based form. After the conversion,
  a tool (see below) is free to do  whatever transformations it would like
  on the IR, before Valgrind translates  the IR back into machine code and
  lets  the host processor run it.

     Callgrind is a profiler build upon that. Main benefit is that you
   don't have to run your aplication for hours to get reliable result.
   Even one second run is sufficient to get rock-solid, reliable
   results, because Callgrind is a non-probing profiler.

  Another tool build upon Valgrind is Massif. I use it to profile heap
  memory usage. It works great. What it does is that it gives you
  snapshots of memory usage -- detailed information WHAT holds WHAT
  percentage of memory, and WHO had put it there. Such information is
  available at different points of time of application run

● SystemTap [[{]]
"https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Deployment_Guide/s1-oprofile-and-systemtap.html

SystemTap is a tracing and probing tool that allows users to study
and monitor the activities of the operating system in fine detail. It
provides information similar to the output of tools like netstat, ps,
top, and iostat; however, SystemTap is designed to provide more
filtering and analysis options for collected information.

˃˃˃˃˃˃While using OProfile is suggested in cases of collecting
data on where and why the processor spends time in a particular area
of code, it is less usable when finding out why the processor stays
idle. ˂˂˂˂˂

You might want to use SystemTap when instrumenting specific places in
code. Because SystemTap allows you to run the code instrumentation
without having to stop and restart the instrumentation, it is
particularly useful for instrumenting the kernel and daemons.

For more information on SystemTap, refer to Section 26.11.2,
“Useful Websites” for the relevant SystemTap documentation. [[}]]
------------------------------------

● google-perftools
 https://code.google.com/p/gperftools/?redir=1
  google-perftools is the only reasonable alternative to gprof I've
found. It's quite usable, familiar, and I believe it's time sampling,
so that IO bottlenecks are revealed, in addition to the usual CPU
bottle necks that gprof discovers. It's also significantly less
invasive.

[[}]]


● Linking ELF  [[{]]
Linking ELF:
objcopy - copy and translate object files
it can be used to generate a raw binary file by using an output target of binary (e.g., use -O binary).  When objcopy
       generates a raw binary file, it will essentially produce a memory dump of the contents of the input object file.  All
       symbols and relocation information will be discarded.  The memory dump will start at the load address of the lowest
       section copied into the output file.
------------------
"Ref: http://permalink.gmane.org/gmane.comp.gnu.binutils/11292:
turning (part of) an executable into a shared objectI have executables with some extra read-only data in a non-standard section
 ("".debug_cfg"" instead of "".data"" or "".rodata"").  I would like to take a linked executable and extract just this data into a
standalone file.  Furthermore, I would like the extracted data to be navigable by an unrelated application using dlopen() and
 dlsym().  I am working on a Linux x86 box with ELF binaries, and while portability is always welcome, that specific platform is
 currently my top priority.

Extracting the special section is easy enough using objcopy.  My gcc section attributes notwithstanding, it appears that pointed-to
 strings in the extra data actually end up in the "".rodata"" section rather than the "".debug_cfg"" section.  So we keep both:

     % objcopy -j .debug_cfg -j .rodata executable extracted-data

gcc is perfectly willing to turn that extracted data into a shared object:

     % gcc -shared -o extracted-data.so extracted-data

I can write a program that dlopen()'s this shared object and uses dlsym() to fetch the address of a symbol that I know should be
 present in the "".debug_cfg"" section.  That symbol refers to a structure containing string pointer fields, non-string pointer
 fields, and non-pointer fields.  The string pointer fields should point into "".rodata"", while the non-string pointer fields
always point to other data also in the "".debug_cfg"" section.  What I find, is that the non-pointer fields have correct values,
 but the pointer fields do not.

Presumably we lost some important reloc information when we linked the executable.  We can explicitly ask the linker to keep
 that information around.  Unfortunately, that leads to an error when turning the extracted data into a shared object:

     % gcc -Wl,--emit-relocs -o executable [...]
     % objcopy -j .debug_cfg -j .rodata executable extracted-data
     % gcc -shared -o extracted-data.so extracted-data
     /usr/bin/ld: simple-cfg.sec(.debug_cfg+0x8048400): reloc against \
     `.rodata': error 2

It looks like the "".rel.dyn"" section contains relocation information. Perhaps I need to keep that too?  No luck:

     % gcc -Wl,--emit-relocs -o executable ...
     % objcopy -j .debug_cfg -j .rodata -j .rel.dyn executable \
     extracted-data
     % gcc -shared -o extracted-data.so extracted-data
     /usr/bin/ld: simple-cfg.sec(.debug_cfg+0x8048400): reloc against \
     `.rodata': error 2

Is there any way to make this alchemical trick work?  How can I extract selected data sections from a linked executable and
 turn them back into a shared, dynamically loadable object with properly adjusted pointers?

-------------------------
http://gcc.gnu.org/ml/gcc-help/2012-10/msg00159.html
From: Michael Zintakis ˂michael dot zintakis at googlemail dot com˃
I'm only not sure if the kernel know all the sorts of ELF sections and segments ld.so can handle.
Probably you'll need to modify kernel code to walk over DYNAMIC
segment (which keeps the list of dependencies) to verify the shared
objects an application depends on.
It looks as though I have to reconsider my initial approach - even
though I could read that segment (not an easy task though), there is
no way the kernel alone could find all dependencies based on that
section (there could be .so files, which have dependencies on other
.so files and so on), so I have to change ld.so in order to be able
to do what the kernel does and verify the files to be loaded. That
would be in addition to the kernel doing the verification of the
initial executable.

Yes, but a statically linked executable can also call dlopen(),
mmap() (As it was noted later).

Yep, and given what I wrote in the previous paragraph above, it looks
as though ld.so also needs to be capable of doing the verification.

On a slightly brighter node, (dynamically) adding new sections to ELF
turned out to be an easy task, even if the executable/.so file is
already compiled/built - all I have to do is execute ""objcopy
--add-section ˂section_name˃=˂section_file˃ ˂infile˃"" and then
""objcopy --set-section-flags ˂section_name˃=˂flags˃ ˂infile˃""
to set the appropriate flags to ˂section_name˃ (""readonly"" in my
case). As soon as this is done, the section is added (with its
content set from the content of ˂section_file˃) and the appropriate
reallocation of the ELF binary is ""automatically"" done by objcopy.

My initial intent was to create a new section in the ELF header, but
I could not find an easy way to do that either during compile time or
when the executable/.so file is already built, so placing my
""custom"" section in the ELF section header by using objcopy seems a
good choice and I don't have to recompile everything.

Next, I'll look for ways in which the binary/.so loading could be
bypassed (to prevent verification) so that when I change the kernel
and the ld.so code later on, to prevent that from happening and
enforce verification in all cases, when desired.

________________________
"Executable stacks: (nested functions)
http://www.airs.com/blog/archives/518
[[}]]

● MAKE [[{101]]
"C&P from: http://mad-scientist.net/make/rules.html
Paul's Rules of Makefiles
 A somewhat tongue-in-cheek title, but this page lists a few very important rules you should always keep in mind when creating makefiles.
Following these rules will allow your makefiles to be both pithy and beautiful.  And they will make maintaining and modifying them, and thus
your entire life, a much more pleasant experience.

 Use GNU make.

 Don't hassle with writing portable makefiles, use a portable make instead!
  Every non-.PHONY
rule must update a file with the exact name of its target.

 Make sure every command script touches the file ""$@""--
not ""../$@"", or ""$(notdir $@)"", but
exactly $@.  That way you and GNU make always agree.
  Life is simplest if the targets are built in the current working directory.

 Use VPATH to locate the sources from the objects directory, not to locate the objects from the sources directory.
  Follow the Principle of Least Repetition.

 Try to never write a filename more than once.  Do this through a combination of make variables, pattern rules, automatic variables, and GNU
make functions.  Every non-continued line that starts with a TAB is part of a command script--and vice versa.

 If a non-continued line does not begin with a TAB character, it is never part of a command script: it is always interpreted as makefile syntax.
 If a non-continued line does begin with a TAB character, it is always part of a command script: it is never interpreted as makefile syntax.

 Continued lines are always of the same type as their predecessor, regardless of what characters they start with.


 Yes, that's all of them... so far.  It's not that that's all I have to say on the subject, but coming up with points which are both truly fundamental
and expressible in a succinct rule format, ain't easy.

 Let me know if you have suggestions.

Paul D. Smith
˂psmith@gnu.org˃"
"Quick Reference:
Appendix A Quick Reference
This appendix summarizes the directives, text manipulation functions, and special variables which GNU make understands.
See Special Targets, Catalogue of Implicit Rules, and Summary of Options, for other summaries.
   Here is a summary of the directives GNU make recognizes:
define variable define variable =define variable :=define variable ::=define variable +=define variable ?=endefDefine multi-line variables.
See Multi-Line. undefine variableUndefining variables.
See Undefine Directive.
ifdef variableifndef variableifeq (a,b)ifeq ""a"" ""b""ifeq 'a' 'b'ifneq (a,b)ifneq ""a"" ""b""ifneq 'a' 'b'elseendif Conditionally evaluate part of the makefile.
override variable-assignmentDefine a variable, overriding any previous definition, even one from the command line.
See The override Directive.
export Tell make to export all variables to child processes by default.
See Communicating Variables to a Sub-make.
export variableexport variable-assignmentunexport variableTell make whether or not to export a particular variable to child processes.
See Communicating Variables to a Sub-make.
private variable-assignmentDo not allow this variable assignment to be inherited by prerequisites.

See Suppressing Inheritance.

vpath pattern pathSpecify a search path for files matching a ‘%’ pattern.

See The vpath Directive.

vpath patternRemove all search paths previously specified for pattern.

vpathRemove all search paths previously specified in any vpath directive.

Here is a summary of the built-in functions (see Functions):

 $(subst from,to,text)Replace from with to in text.

See Functions for String Substitution and Analysis.

$(patsubst pattern,replacement,text)Replace words matching pattern with replacement in text.

See Functions for String Substitution and Analysis.

$(strip string)Remove excess whitespace characters from string.

See Functions for String Substitution and Analysis.

$(findstring find,text)Locate find in text.

See Functions for String Substitution and Analysis.


$(filter pattern...,text)Select words in text that match one of the pattern words.

See Functions for String Substitution and Analysis.


$(filter-out pattern...,text)Select words in text that do not match any of the pattern words.

See Functions for String Substitution and Analysis.


$(sort list)Sort the words in list lexicographically, removing duplicates.

See Functions for String Substitution and Analysis.


$(word n,text)Extract the nth word (one-origin) of text.

See Functions for String Substitution and Analysis.


$(words text)Count the number of words in text.

See Functions for String Substitution and Analysis.


$(wordlist s,e,text)Returns the list of words in text from s to e.

See Functions for String Substitution and Analysis.


$(firstword names...)Extract the first word of names.

See Functions for String Substitution and Analysis.


$(lastword names...)Extract the last word of names.

See Functions for String Substitution and Analysis.


$(dir names...)Extract the directory part of each file name.

See Functions for File Names.


$(notdir names...)Extract the non-directory part of each file name.

See Functions for File Names.


$(suffix names...)Extract the suffix (the last ‘.’ and following characters) of each file name.

See Functions for File Names.


$(basename names...)Extract the base name (name without suffix) of each file name.

See Functions for File Names.


$(addsuffix suffix,names...)Append suffix to each word in names.

See Functions for File Names.


$(addprefix prefix,names...)Prepend prefix to each word in names.

See Functions for File Names.


$(join list1,list2)Join two parallel lists of words.

See Functions for File Names.


$(wildcard pattern...)Find file names matching a shell file name pattern (not a
‘%’ pattern).

See The Function wildcard.


$(realpath names...)For each file name in names, expand to an absolute name that
does not contain any ., .., nor symlinks.

See Functions for File Names.


$(abspath names...)For each file name in names, expand to an absolute name that
does not contain any . or .. components, but preserves
symlinks.

See Functions for File Names.


$(error text...)When this function is evaluated, make generates a fatal error
with the message text.

See Functions That Control Make.


$(warning text...)When this function is evaluated, make generates a warning with
the message text.

See Functions That Control Make.


$(shell command)Execute a shell command and return its output.

See The shell Function.


$(origin variable)Return a string describing how the make variable variable was
defined.

See The origin Function.


$(flavor variable)Return a string describing the flavor of the make variable
variable.

See The flavor Function.


$(foreach var,words,text)Evaluate text with var bound to each word in words,
and concatenate the results.

See The foreach Function.


$(if condition,then-part[,else-part])Evaluate the condition condition; if it's non-empty substitute
the expansion of the then-part otherwise substitute the
expansion of the else-part.

See Functions for Conditionals.


$(or condition1[,condition2[,condition3...]])Evaluate each condition conditionN one at a time; substitute the
first non-empty expansion.  If all expansions are empty, substitute
the empty string.

See Functions for Conditionals.


$(and condition1[,condition2[,condition3...]])Evaluate each condition conditionN one at a time; if any
expansion results in the empty string substitute the empty string.  If
all expansions result in a non-empty string, substitute the expansion
of the last condition.

See Functions for Conditionals.


$(call var,param,...)Evaluate the variable var replacing any references to $(1),
$(2) with the first, second, etc. param values.

See The call Function.


$(eval text)Evaluate text then read the results as makefile commands.
Expands to the empty string.

See The eval Function.


$(file op filename,text)Expand the arguments, then open the file filename using mode
op and write text to that file.

See The file Function.


$(value var)Evaluates to the contents of the variable var, with no expansion
performed on it.

See The value Function.


   Here is a summary of the automatic variables.
See Automatic Variables,
for full information.

     $@The file name of the target.


$%The target member name, when the target is an archive member.


$˂The name of the first prerequisite.


$?The names of all the prerequisites that are
newer than the target, with spaces between them.
For prerequisites which are archive members, only
the named member is used (see Archives).


$^$+The names of all the prerequisites, with spaces between them.  For
prerequisites which are archive members, only the named member is used
(see Archives).  The value of $^ omits duplicate
prerequisites, while $+ retains them and preserves their order.


$*The stem with which an implicit rule matches
(see How Patterns Match).


$(@D)$(@F)The directory part and the file-within-directory part of $@.


$(ºD)$(ºF)The directory part and the file-within-directory part of $*.


$(%D)$(%F)The directory part and the file-within-directory part of $%.


$(˂D)$(˂F)The directory part and the file-within-directory part of $˂.


$(^D)$(^F)The directory part and the file-within-directory part of $^.


$(+D)$(+F)The directory part and the file-within-directory part of $+.


$(?D)$(?F)The directory part and the file-within-directory part of $?.


   These variables are used specially by GNU make:

     MAKEFILES
Makefiles to be read on every invocation of make. See The Variable MAKEFILES.
VPATH Directory search path for files not found in the current directory. See VPATH Search Path for All Prerequisites.

SHELL The name of the system default command interpreter, usually /bin/sh.  You can set SHELL in the makefile to change the shell used to run recipes.  See Recipe Execution.  The SHELL variable is handled specially when importing from and exporting to the environment.  See Choosing the Shell.


MAKESHELL On MS-DOS only, the name of the command interpreter that is to be used by make.  This value takes precedence over the value of SHELL.  See MAKESHELL variable.


MAKE The name with which make was invoked.  Using this variable in recipes has special meaning.  See How the MAKE Variable Works.


MAKE_VERSION The built-in variable ‘MAKE_VERSION’ expands to the version number of the GNU make program.


MAKE_HOST The built-in variable ‘MAKE_HOST’ expands to a string representing the host that GNU make was built to run on.


MAKELEVEL The number of levels of recursion (sub-makes). See Variables/Recursion.


MAKEFLAGS The flags given to make.  You can set this in the environment or a makefile to set flags.

See Communicating Options to a Sub-make. It is never appropriate to use MAKEFLAGS directly in a recipe line: its contents may not be quoted correctly for use in the shell.  Always allow recursive make's to obtain these values through the environment from its parent.

GNUMAKEFLAGS Other flags parsed by make.  You can set this in the environment or a makefile to set make command-line flags.  GNU make never sets this variable itself.  This variable is only needed if you'd like to set GNU make-specific flags in a POSIX-compliant makefile.  This variable will be seen by GNU make and ignoredby other make implementations.  It's not needed if you only use GNU make; just use MAKEFLAGS directly. See Communicating Options to a Sub-make.


MAKECMDGOALS The targets given to make on the command line.  Setting thisvariable has no effect on the operation of make. See Arguments to Specify the Goals.


CURDIR Set to the pathname of the current working directory (after all -C options are processed, if any).  Setting this variable has no effect on the operation of make.

See Recursive Use of make.

SUFFIXES The default list of suffixes before make reads any makefiles.
.LIBPATTERNSDefines the naming of the libraries make searches for, and their order.

See Directory Search for Link Libraries. "
[[}]]

● String manipulation  [[{101.strings]]
http://www.rainydayz.org/beej/bgc/stringref.html
[[}]]

● gcc [[{]]
  $ gcc
    -g                     // add debugging info
    -Idir1 -Idir2          <-- Add directory to include search path
    -D_FORTIFY_SOURCE=2
    -D_ISOC99_SOURCE       <-- The GNU C Library nevertheless has a complete ISOC99 implementation of the standard. Use this macro to activate. This is actually a libc option, not a compiler option. http://www.gnu.org/software/libc/manual/html_node/Feature-Test-Macros.html
    -std=c99
    -D_FILE_OFFSET_BITS=64  <-- Usefull for apps with large files (Video, big databases,..)
    -D_LARGEFILE_SOURCE
    -D_POSIX_C_SOURCE=200112
    -D_XOPEN_SOURCE=600
    -O2   // Code Optimization level
    -fstack-protector
    --param=ssp-buffer-size=4
    -Wformat
    -Werror=format-security
    -fomit-frame-pointer
    -pthread // <-- activate posix trheads
    -Wall
    -fno-math-errno
    -fno-signed-zeros
    -fno-tree-vectorize
    -MMD
    -MF lua_avconv.d
    -MT lua_avconv.o
    -c
    -o lua_avconv.o lua_avconv.c
[[}]]

● https://eli.thegreenplace.net/tag/c-c  [[{]]
2019.11.23:     "Beating" C with 400 lines of unoptimized assembly
2019.07.22:     Faster XML stream processing in Go
2019.07.15:     Passing callbacks and pointers to Cgo
2018.12.05:     Type erasure and reification
2018.10.17:     Covariance and contravariance in subtyping
2018.09.04:     Measuring context switching and memory overheads for Linux threads
2018.08.01:     Launching Linux threads and processes with clone
2018.07.13:     Basics of Futexes
2017.12.07:     Concurrent Servers: Part 5 - Redis case study
2017.11.09:     Concurrent Servers: Part 4 - libuv
2017.10.06:     Concurrent Servers: Part 3 - Event-driven
2017.10.04:     Concurrent Servers: Part 2 - Threads
2017.10.02:     Concurrent Servers: Part 1 - Introduction
2016.12.06:     Basics of using the readline library
2016.05.12:     The Expression Problem and its solutions
2016.05.05:     On the Composite and Interpreter design patterns
2016.04.19:     A polyglot's guide to multiple dispatch
2016.03.12:     gRPC sample in C++ and Python
2016.03.04:     Returning multiple values from functions in C++
2016.02.22:     C++: RAII without exceptions
2016.02.16:     The promises and challenges of std::async task-based parallelism in C++11
2016.01.17:     C++11 threads, affinity and hyperthreading
2015.08.21:     C++: Deleting destructors and virtual operator delete
2015.07.15:     Programmatic access to the call stack in C++
2015.05.18:     On parsing C, type declarations and fake headers
2014.11.11:     Samples for using LLVM and Clang as a library
2014.11.03:     Perfect forwarding and universal references in C++
2014.10.24:     Variadic templates in C++
2014.10.20:     SFINAE and enable_if
2014.01.07:     Getting started with libjit - part 3
2013.12.05:     The cost of dynamic (virtual calls) vs. static (CRTP) dispatch in C++
2013.12.03:     Intel i7 loop performance anomaly
2013.11.12:     Getting started with libjit - part 2
2013.11.05:     How to JIT - an introduction
2013.10.17:     Getting started with libjit - part 1
2013.03.04:     Flexible runtime interface to shared libraries with libffi
2012.12.17:     Dumping a C++ object's memory layout with Clang
2012.08.24:     Plugins in C
2012.08.13:     How statically linked programs run on Linux
2012.07.12:     Computed goto for efficient dispatch tables
2012.07.05:     How Clang handles the type / variable name ambiguity of C/C++
2012.06.28:     The type / variable name ambiguity in C++
2012.06.20:     C++11: using unique_ptr with standard library containers
2012.06.17:     Faster XML iteration with ElementTree
2012.06.08:     Basic source-to-source transformation with Clang
2012.02.06:     Dependent name lookup for C++ templates
2012.02.03:     Adventures in parsing C: ASTs for switch statements
2012.01.03:     Understanding the x64 code models
2011.12.15:     Understanding lvalues and rvalues in C and C++
2011.11.30:     How I stopped worrying and switched to C++ for my Bob Scheme VM
2011.11.14:     Anonymous functions (lambdas) in C++11
2011.11.11:     Position Independent Code (PIC) in shared libraries on x64
2011.11.03:     Position Independent Code (PIC) in shared libraries
2011.09.16:     Exporting C++ classes from a DLL
2011.08.30:     Construction of function static variables in C++ is not thread safe
2011.08.25:     Load-time relocation of shared libraries
2011.07.09:     Passing extra arguments to Qt slots
2011.07.08:     DLL hell problems with Qt Creator
2011.07.03:     Parsing C++ in Python with Clang
2011.05.17:     The Curiously Recurring Template Pattern in C++
2011.05.02:     The context sensitivity of C’s grammar, revisited
2011.04.22:     C++ template syntax patterns
2011.04.09:     A C++ VM added to Bob
2011.03.20:     Boost.Asio with Protocol Buffers code sample
2011.03.08:     Non-constant global initialization in C and C++
2011.03.07:     From C to AST and back to C with pycparser
2011.03.04:     Building protobuf examples on Windows with MSVC
2011.02.17:     The many faces of operator new in C++
2011.02.15:     Array initialization with enum indices in C but not C++
2011.01.14:     How Python affected my C/C++ brace style
2010.11.13:     Pure virtual destructors in C++
2010.10.31:     pycparser now supports C99
2010.06.11:     The perils of unsigned iteration in C/C++
2010.04.06:     Pointers vs. arrays in C, part 2(D)
2010.04.05:     pthreads as a case study of good API design
2010.01.11:     Pointers to arrays in C
2009.11.23:     Visualizing binary trees with Graphviz
2009.11.16:     void* and casts, in C and C++
2009.10.30:     Handling out-of-memory conditions in C
2009.10.21:     Are pointers and arrays equivalent in C?
2009.10.17:     The C++ bashing season is back
2009.10.07:     Book review: "C Interfaces and Implementations" by David R. Hanson
2009.09.23:     Compiling SQLite on Windows
2009.04.27:     Using goto for error handling in C
2009.01.28:     Creating threads in Win32 C/C++ programming
2008.10.18:     Implementing cdecl with pycparser
2008.10.17:     memmgr - a fixed-pool memory allocator
2008.08.31:     ctypes - calling C/C++ code from Python
2008.07.18:     Reading C type declarations
2007.11.24:     The context sensitivity of C's grammar
2006.12.04:     Compiling C DLLs and using them from Perl
2006.12.03:     A complete C++ development environment from Microsoft, free
2006.03.03:     unit testing framework - cxxtext
2005.12.04:     perl master, C++ slave, bound for serial port programming
2005.08.11:     eclipse
2005.07.15:     Qt guidelenes for API design
2005.06.10:     lesson for today: caveat in C++ line-reading
2005.06.01:     PIC compiler bugs...
2005.03.22:     c++ woes: std:: and unwanted warnings
2005.03.08:     Book review: "Expert C Programming" by Peter van der Linden
2005.02.01:     true cross-platform compatibility of Qt
2005.01.02:     Qt - first impressions
2004.12.27:     serial port saga - a C++ implementation
2004.10.01:     complying with -Wall -pedantic -ansi
2004.07.30:     a cool algorithm for counting ones in a bitstring
2004.07.18:     c/c++ annoyance - unsigned iteration
2004.06.18:     back to geekiness: hash_map
2004.06.01:     nostalgic...
2004.05.18:     Book review: "Efficient C++: Performance Programming Techniques" by Bulka & Mayhew
2004.05.14:     making sense of pointers
2004.04.21:     a problem, two tricks - almost a solution
2004.04.11:     compiling gcc
2003.12.26:     Finding out where a function was called from
2003.12.26:     Initialization of structures and arrays in C++
2003.12.09:     Book review: "Effective STL" by Scott Myers
2003.09.19:     cpp is pain
2003.09.12:     Book review: "C++ in action" by Bartosz Milewski
2003.09.05:     more on simplified cpp + some rant
2003.09.04:     coding a simplified cpp
2003.08.29:     note to self - assert()
2003.07.23:     Variable initialization in C++
2003.07.23:     Allocating multi-dimensional arrays in C++
2003.07.23:     Correct usage of const with pointers
2003.07.04:     interesting problem (binary representation of big numbers)
2003.06.27:     "Modern C++" scares me
2003.05.16:     too much Perl...
2003.05.09:     Coding in C++, wishing it were Lisp (or Perl)
[[}]]

● "C/C++ visibility:
  http://www.ibm.com/developerworks/aix/library/au-aix-symbol-visibility/index.html?ca=drs-

● https://code.google.com/p/address-sanitizer/
  AddressSanitizer (ASan) is a fast memory error detector.
  It finds use-after-free and {heap,stack,global}-buffer overflow bugs in C/C++ programs.

● https://github.com/preservim/tagbar
  Vim plugin: easy way to browse the tags of the current file and get
  an overview of its structure in a sidebar.
  For example methods in C++ are displayed under the class they are defined in

● gdb pretty printer [[{]]
 https://undo.io/resources/gdb-watchpoint/here-quick-way-pretty-print-structures-gdb/

- Using pretty-printers can save lot of time staring at your computer screen and
  improve the flow of your debugging too!

In this tutorial, I start off with writing a basic pretty-printer to
display the value of the si_signo field in the siginfo_t structure,
before doing some more advanced stuff.


Why we need pretty-printers

We love debugging in GDB. We all use structures and classes in the
code we write, and GDB strives to display what these are but misses
the contextual information; when you use a handful of members, and in
particular unions, then interpreting these more complicated
structures quickly becomes overwhelming.

When GDB prints a value, it first checks whether there is a
pretty-printer registered for that value. If there is, then GDB uses
the pretty-printer to display the value. Otherwise, the value prints
in the usual way.

For example, in my previous tutorial, I used the print info command
to confirm whether the inferior program received my Ctrl-C. But,
because I didn't have a pretty-printer for the siginfo_t structure,
the command returned all the data of the structure, including
expanding the many unions that structure uses.

Output - Print Info

Messy and not easy to read.
See how easily you can write a basic pretty-printer

To start off, we write a basic pretty-printer that returns the
si_signo value from the siginfo_t structure for an interrupt signal
that the inferior program receives.

Almost every pretty-printer comprises of two main elements:

    The lookup function to identify the value type, and
    the printer function itself.

We write our program in Python.

$ vim prettyprint.py

# Start off with defining the printer as a Python object.

class SiginfoPrinter:

  # The constructor takes the value and stores it for later.

  def __init__(self, val):
    self.val = val

  # The to_string method returns the value of the
  # si_signo attribute of the directory.

  def to_string(self):
    signo = self.val['si_signo']
    return str(signo)

# Next, define the lookup function that returns the
# printer object when it receives a siginfo_t.

# The function takes the GDB value-type, which, in
# our example is used to look for the siginfo_t.

def my_pp_func(val):
  if str(val.type) == 'siginfo_t': return SiginfoPrinter(val)

# Finally, append the pretty-printer as object/ function to
# the list of registered GDB printers.

gdb.pretty_printers.append(my_pp_func)

# Our pretty-printer is now available when we debug
# the inferior program in GDB.

Now, run your inferior program and hit Ctrl-C to quit. Our
pretty-printer returns the value 2; the value for a SIGINT.

(gdb) source prettyprint.py
(gdb) print info
$4 = 2
(gdb)

Much easier to read.

I demonstrate this basic pretty-printer in my video. Do watch it here.

Of course, we can and should improve our printer. In my next example,
I print the textual name of the si_signo member. I use a file called
signames,  which simply contains a list of the signal numbers with
their corresponding textual signal names.

class SiginfoPrinter:

  def _init_(self, val):
    self.val = val

  # Watch the variable type that you print.
  # signames is an object and takes an integer variable.

  def to_string(self):
    signo = int (self.val['si_signo'])
    signame = signames[signo]
    return str(signo) + ' ('+ signame +')'

def my_pp_func(val):
  if str(val.type) == 'siginfo_t': return SiginfoPrinter(val)

gdb.pretty_printers.append(my_pp_func)

When we run our inferior program again and hit Ctrl-C to quit, now
the printer returns the value 2, plus the textual name SIGINT.

(gdb) source signames.py
(gdb) source prettyprint.py
(gdb) print info
$5 = 2 (SIGINT)
(gdb)

 That’s pretty easy.

UDB Time Travel Debugger
Find and fix bugs in minutes  - including C/C++ concurrency issues
Learn more »
Are you ready to build out the pretty-printer some more?

The possibilities are endless. You can extract and print any value of
a member in a structure with your pretty-printer program. In my next
example, I use the code field to identify the kill signal, but also
return the sender of that kill command.

class SiginfoPrinter:

  def __init__(self, val):
    self.val = val

  def to_string(self):
    signo = int(self.val['si_signo'])

    # Determine the signal with the code member,
    # for example, 0 = kill, and 128 = Ctrl-C.

    code = int(self.val['si_code'])
    signame = signames[signo]

    # Determine sender of the kill with the union _sifields

    sender = self.val['_sifields']['_kill']['si_pid']

    # If the signal is a kill (code =0) then print sender.

    if code == 0:
      return str(signo) + ' ('+ signame +') sender = '+ str(sender)

    # For any other signal print the code.

    return str(signo) + ' ('+ signame +') code = '+ str(code)

def my_pp_func(val):
  if str(val.type) == 'siginfo_t': return SiginfoPrinter(val)

db.pretty_printers.append(my_pp_func)

Writing pretty-printers pays off

That is it. We now have a pretty-printer for the siginfo_t structure.
But, of course, you can extrapolate this handy printer to display
whatever structure you want.

Investing a very small amount of time in creating your
pretty-printers upfront pays off quickly and almost certainly moves
up your debugging a couple of gears. You will find that you become
more productive and write code you can be truly proud of.

Consider making a gdbinit per project, and committing to your
project’s source control so that everyone working on that project
can benefit.

Job done!

In my video, I do explain and run all the code I have written in this
tutorial, so I do encourage you to watch it here.

https://undo.io/resources/gdb-watchpoint/debugging-pretty-printers-gdb-part2/
gdbWatchPoint


Debugging with pretty printers in GDB - part 2
Last updated 24th Jun 2021

In this tutorial, Software Architect Mark Williamson follows on from
Greg's tutorial on Debugging with pretty-printers in GDB by
illustrating how to write pretty printers for more complex data
structures.
Getting to the point_t

Our examples in this tutorial will revolve around data structures
from an imaginary vector graphics program.  As we work up to more
complex geometry types we will extend to our pretty printers to help
us understand the structures involved.

We’ll start with a very fundamental structure, representing a
single point:

typedef struct {
    int x;
    int y;
} point_t;

Lets suppose our program has defined an instance of this type,
representing a point in 2D space:

point_t p = {
    .x = 1,
    .y = 2,
};

Printing this immediately in GDB gives us a fairly familiar, though
not particularly compact, representation:

(gdb) print p
$9 = {
 x = 1,
 y = 2
}

In our previous examples, we already learnt how to write a basic
pretty printer. A similar pretty-printer script for our point_t might
look like this:

import gdb

class PointPrinter:
    def __init__(self, val):
        self.val = val
    def to_string(self):
        return '({x}, {y})'.format(
            x=self.val['x'],
            y=self.val['y']
        )

def my_pp_func(val):
    if str(val.type) == 'point_t': return PointPrinter(val)
    return None

gdb.pretty_printers.append(my_pp_func)

This gives us a more compact output format that’s more suitable for
the coordinate data we’re representing:

(gdb) print p
$8 = (1, 2)

Line up for nested structures!

Our point_t structure is very likely to be used as an element of
other data structures. For instance, in a drawing program, we might
have a line_t that contains two points:

typedef struct {
    point_t start;
    point_t end;
} line_t;

Let’s assume we’d like to pretty print this too. We could just
copy-and-paste the code from the previous pretty-printer with some
edits:

...
    def to_string(self):
        return '<({x1}, {y1}), ({x2}, {y2})>'.format(
            x1=self.val['start']['x'],
            y1=self.val['start']['y'],
            x2=self.val['end']['x'],
            y2=self.val['end']['y']
        )
...

But this is already getting a bit repetitive. Fortunately, GDB
already has this covered for us: when formatting strings for
printing, it will recursively call existing pretty printers. So,
actually, we can write:

class PointPrinter:
    ...

class LinePrinter:
    def __init__(self, val):
        self.val = val
    def to_string(self):
        return '<{p1}, {p2}>'.format(
            p1=self.val['start'], p2=self.val['end']
        )

def my_pp_func(val):
    if str(val.type) == 'point_t': return PointPrinter(val)
    elif str(val.type) == 'line_t': return LinePrinter(val)
    return None

gdb.pretty_printers.append(my_pp_func)

Which produces the output:

(gdb) print l
$7 = <(3, 4), (5, 6)>

Deferring formatting decisions to existing pretty printers also means
that formatting changes can be made in one place and reflected
everywhere. For instance, if we now change our original PointPrinter
to say:

...
    def to_string(self):
        return 'Point({x}, {y})'.format(
            x=self.val['x'],
            y=self.val['y']
        )
...

Then we’ll see also this reflected when we print a line_t:

(gdb) print l
$8 = <Point(3, 4), Point(5, 6)>

More complex data structures - let GDB do the walk

We can also use pretty printers to handle more complicated data
structures, for instance ones that use pointers to chain together
multiple constituent structs.

Our vector drawing program will need a data structure to record all
of the objects in the system. This structure allows us to track all
the allocated points and lines:

struct drawing_element;
typedef struct drawing_element {
    enum {
        ELEMENT_POINT,
        ELEMENT_LINE
    } kind;
    union element {
        point_t *point;
        line_t *line;
    } el;
    struct drawing_element *next; /* NULL-terminated */
} drawing_element_t;

Note that this can be an arbitrarily large data structure. For our
example here, let's just chain together a couple of elements:

drawing_element_t last = {
    .kind = ELEMENT_POINT,
    .el = {
        .point = &p,
    },
    .next = NULL,
};

drawing_element_t head = {
    .kind = ELEMENT_LINE,
    .el = {
        .line = &l,
     },
     .next = &last,
};

Printing it won’t provide very helpful output by default, even with
our existing pretty printers:

(gdb) print head

$1 = {
 kind = ELEMENT_LINE,
 el = {
   point = 0x7fffffffd980,
   line = 0x7fffffffd980
 },
 next = 0x7fffffffd960
}

We can see the enum value of kind - which is helpful. Other than
that, we just have a pair of pointers to the el member and a next
pointer. We could walk along these pointers manually but it would be
much nicer if GDB could do that work for us.

If we write a pretty printer for the drawing_element_t then we can
build a more complex string renderer that will walk the data
structure and give us a summary. To do this, we’ll define a
children() method, which tells GDB that the type it’s pretty
printing somehow contains other values of interest:

class DrawingElementPrinter:
    def __init__(self, val):
        self.val = val

    def to_string(self):
        # Describe the overall container structure.
        return 'drawing_element_t @ {}'.format(self.val.address)

    def children(self):
        curr = self.val
        enum_type = self.val['kind'].type
        while curr:
            # For each drawing_element_t in the list, check “kind” and
            # choose the point_t or line_t pointer as appropriate.
            if curr['kind'] == enum_type['ELEMENT_POINT'].enumval:
                el_ptr = curr['el']['point']
            elif curr['kind'] == enum_type['ELEMENT_LINE'].enumval:
                el_ptr = curr['el']['line']

            # Prepare for next loop.
            curr = curr['next'].dereference() if curr['next'] != 0 else None

            # Yield the child element - a string name and the value
            # we want to show.
            yield 'el', el_ptr.dereference()

    def display_hint(self):
        # Tell GDB how to display the output of children().
        return 'array'  # Format our sequence like an array’s contents.

def my_pp_func(val):
    if str(val.type) == 'point_t': return PointPrinter(val)
    elif str(val.type) == 'line_t': return LinePrinter(val)
    elif str(val.type) == 'drawing_element_t':
        return DrawingElementPrinter(val)
    return None

gdb.pretty_printers.append(my_pp_func)

This pretty printer will:

    Display the location of our data structure
    Walk the linked list to retrieve all the elements
    For each element, use the kind field to determine its type
    Delegate display of that element to the existing pretty printer
    (by dereferencing the appropriate pointer)

By combining these elements, we have built a pretty printer for the
whole chained data structure rather than for a single value. When we
try our print command again, we’ll see something much more
interesting:

(gdb) p head
$2 = drawing_element_t @ 0x7fffffffd820 = {<Point(3, 4), Point(5, 6)>, Point(1, 2)}

Since we selected the “array” display hint, this will
automatically reflect preferences for printing arrays (as set by set
print array).

The printer we’ve built will automatically walk a list of arbitrary
length; with the full power of Python available, combined with
GDB’s access to data values and types, it is possible to decode
arbitrarily complex data structures.

That’s it for this tutorial - we’ve seen how GDB can
automatically invoke the right pretty printer to display your data
and handle more advanced data structures. Use these techniques and
you’ll get a better debug experience for less effort spent.

The full source of the examples shown above can be downloaded for reference:

    geometry.c
    printers.py
[[}]]

● C/C++: How different programming languages read and write data [[{101.I/O]]
https://opensource.com/article/21/7/programming-read-write
[[}]]

● Memory error checking in C and C++: Comparing Sanitizers and Valgrind
https://developers.redhat.com/blog/2021/05/05/memory-error-checking-in-c-and-c-comparing-sanitizers-and-valgrind

● Instant replay: Debugging C and C++ programs with rr
https://developers.redhat.com/blog/2021/05/03/instant-replay-debugging-c-and-c-programs-with-rr

● C/C++ tutorial, 101: Memory Layout of C Programs
https://www.geeksforgeeks.org/memory-layout-of-c-program/

● https://developers.redhat.com/articles/2021/10/29/beginners-attempt-optimizing-gcc?sc_cid=7013a000002pxeoAAA#finding_a_suitable_gcc_bug

● The utility also tries to minimize its impact on the OS page-cache by [[{performance.storage]]
  using the appropriate posix_fadvise() calls when available.[[}]]


#############################
● libffi: High Leve Language Interface [[{]]
  https://sourceware.org/libffi/

Compilers for high level languages generate code that follows certain
conventions. These conventions are necessary, in part, for separate
compilation to work. One such convention is the "calling convention".
The "calling convention" is a set of assumptions made by the compiler
about where function arguments will be found on entry to a function.
A "calling convention" also specifies where the return value for a
function is found.
Some programs may not know at the time of compilation what arguments
are to be passed to a function. For instance, an interpreter may be
told at run-time about the number and types of arguments used to call
a given function. Libffi can be used in such programs to provide a
bridge from the interpreter program to compiled code.

The libffi library provides a portable, high level programming
interface to various calling conventions. This allows a programmer to
call any function specified by a call interface description at
run-time.

FFI stands for Foreign Function Interface. A foreign function
interface is the popular name for the interface that allows code
written in one language to call code written in another language. The
libffi library really only provides the lowest, machine dependent
layer of a fully featured foreign function interface. A layer must
exist above libffi that handles type conversions for values passed
between the two languages.

The libffi library is useful to anyone trying to build a bridge
between interpreted and natively compiled code. Some notable users
include:
- CPython - the default, most-widely used implementation of the
Python programming language uses libffi in the standard ctypes
library.
- OpenJDK - the open-source implementation of the Java Platform
Standard Edition uses libffi to bridge between the interpreter and
native code for some platforms.
- js-ctypes - a foreign function interface for javascript that
Mozilla will be shipping in Firefox 3.6.
- Dalvik - Dalvik is the virtual machine which runs the Java platform
on Android mobile devices. libffi is used on Android ports for which
no custom bridging code has been written.
- Java Native Access (JNA) - the JNI-free way to call native code
from Java.
- Ruby-FFI - a Foreign Function Interface extension for Ruby.
- fsbv - Foreign Structure By Value is a foreign function interface
library for Common Lisp that extends the standard CFFI package to
include support for passing structure arguments by value.
- JSCocoa - call Objective-C code from javascript on Mac OSX and the
iPhone (via the libffi-iphone port).
- PyObjC - call Objective-C code from Python on Mac OSX.
- RubyCocoa - call Objective-C code from Ruby on Mac OSX.
- The Glasgow Haskell Compiler - call C code from this popular
Haskell implementation.
- Racket - call C code from this popular Scheme implementation.
- gcj - the runtime library for the GNU Compiler for the Java
Programming Language uses libffi to handle calls back and forth
between interpreted and natively compiled code. gcj is part of the
GCC, the GNU Compiler Collection.
[[}]]

● debugging: Blinkenlights
https://justine.lol/blinkenlights/

● C/C++ Intel® oneAPI DPC++ Library - APIs for Heterogeneous Computing
https://www.intel.com/content/www/us/en/developer/tools/oneapi/dpc-library.html

● Dropbox Makes the Android App Faster and More Reliable:
  Swaps C++ Code for a Native Approach
  https://www.infoq.com/news/2022/03/dropbox-android-kotlin/

● C/C++: Cosmopolitan Libc: build-once run-anywhere C library
  https://justine.lol/cosmopolitan/

● C/C++: Time Travel Debug for VS Code
  https://undo.io/resources/time-travel-debug-vscode-extension

● C/C++: New C++ features in GCC 12
https://developers.redhat.com/articles/2022/04/25/new-c-features-gcc-12?sc_cid=7013a0000030ungAAA#acknowledgments

● gcc:
  - Use   -verbose:gc  to get the garbage collection output.
  - If app OutOfMemoryError-crashes, extra info about memory leak
    can be obtained through –XX:HeapDumpOnOutOfMemory , creating a
    heap dump file

● https://gceasy.io/
   Industry's first machine learning guided Garbage collection log
  analysis tool.  GCeasy has in-built intelligence to auto-detect
  problems in the JVM & Android GC logs and recommend solutions to it.

● UDB Time Travel Debugger:
  Find and fix test failures in minutes  - including C/C++ race
  conditions, deadlocks and memory corruptions

[[{01_PM.TODO]]
● cmake  #[cmake_summary] [[{cmake]]
@[https://github.com/tldr-pages/tldr/blob/master/pages/common/cmake.md]
@[https://cmake.org/cmake/help/latest/manual/cmake.1.html]

- Cross-platform build automation system generating recipes
  for native build systems.

  $ cmake $path_to_cmakelist           ← Create build recipe in "./" dir with
                                         CMakeLists.txt from $path_to_cmakelist

  $ cmake $project_dir \               ← Create build recipe
$   -D ${CMAKE_BUILD_TYPE=Release}      ← build type set to Release with CMake variable

  $ cmake --build $build_dir           ← Use generated recipe in $build_dir to build artifacts
                                         Use flag $ --target ${target_name}  for custom build target
  $ cmake --install $build_dir \       ← Install
$   --prefix ${path/to/directory}       ← use custom prefix for install paths (default to /usr/local/)
$  --strip                               ← strip debugging symbols

------------------------------------
• CMake test:
@[https://github.com/tldr-pages/tldr/blob/master/pages/common/ctest.md]
@[https://gitlab.kitware.com/cmake/community/wikis/doc/ctest/Testing-With-CTest]

  $ ctest --output-on-failure \   ← Run 1+/all tests defined in CMake project
$         -j${4}             \     ← Exec up to 4 jobs in parallel
$         -R '^${test_name}$'      ← Run just test whose name matches regex
[[}]]


● Tiny C Compiler - By Fabric Bellard [[{]]
@[https://github.com/yuchao86/tcc]
Tiny C Compiler - C Scripting Everywhere - The Smallest ANSI C compiler
Features:
    SMALL! You can compile and execute C code everywhere, for example
on rescue disks.

    FAST! tcc generates optimized x86 code. No byte code overhead.
Compile, assemble and link about 7 times faster than 'gcc -O0'.

    UNLIMITED! Any C dynamic library can be used directly. TCC is
heading torward full ISOC99 compliance. TCC can of course compile
itself.

    SAFE! tcc includes an optional memory and bound checker. Bound
checked code can be mixed freely with standard code.

    Compile and execute C source directly. No linking or assembly
necessary. Full C preprocessor included.

    C script supported : just add '#!/usr/local/bin/tcc -run' at the
first line of your C source, and execute it directly from the command
line.
[[}]]

● HPX: distributed C++ lib [[{architecture.distributed]]
  - distributed C++ library for concurrency and parallelism.
  - implements APIs defined in the C++ Standard Library and extends them
    to work in a distributed memory space exposing a unified programing
    model which transparently utilizes available resources.
  - Closely aligned with C++ Standard standardization process.
[[}]]

● Compile 3x faster [[{gcc.TODO]]
https://developers.redhat.com/blog/2019/05/15/2-tips-to-make-your-c-projects-compile-3-times-faster/
[[}]]

● Control Make verbosity [[{make,TODO]]
@[https://stackoverflow.com/questions/8438661/control-the-output-of-a-make-command-to-be-less-verbose-dont-echo-each-command/22786988#22786988]
[[}]]

● udis86: Minimalistic Disassembler  [[{]]
@[http://udis86.sourceforge.net/]
- easy-to-use, minimalistic disassembler library (libudis86)
  for the x86 class of instruction set architectures.
- It has a convenient interface for use in the analysis and
  instrumentation of binary code. Udis86 is distributed under
  the terms of the 2-clause BSD License.
$ echo "65 67 89 87 76 65 54 56 78 89 09 00 87" | udcli -32 -x
0000000000000000 656789877665    mov [gs:bx+0x6576], eax
0000000000000000 54              push esp
0000000000000000 56              push esi
0000000000000000 7889            js 0x93
0000000000000000 0900            or [eax], eax
[[}]]

● g-speak: [[{01_PM.TODO]]
@[https://www.oblong.com/g-speak]
g-speak™ is a C/C++ SDK which enables the development of
multi-user, multi-screen, multi-device, spatial, distributed
applications.
[[}]]

● ASTRÉE: Static Analyzer  [[{qa.code.analyzer]]
David Monniaux (CNRS), member of the ASTRÉE project, says: “ASTRÉE is a
static analyzer based on abstract interpretation that aims at proving the
absence of runtime errors in safety-critical software written in a subset of
the C programming language.”

“Automatically analyzing programs for exactly checking properties such as the
absence of runtime errors is impossible in general, for mathematical reasons.
Static analysis by abstract interpretation works around this impossibility
and proves program properties by over-approximating the possible behaviors of
the program: it is possible to design pessimistic approximations that, in
practice, allow proving the desired property on a wide range of software
.”

“So far, ASTRÉE has proved the absence of runtime errors in the primary
control software of the Airbus A340 family. This would be impossible by
software testing, for testing only considers a limited subset of the test
cases, while abstract interpretation considers a superset of all possible
outcomes of the system.”

“ASTRÉE is written in OCaml and is about 44000 lines long (plus external
libraries). We needed a language with good performance (speed and memory usage
) on reasonable equipment, easy support for advanced data structures, and
type and memory safety. OCaml also allows for modular, clear and compact
source code and makes it easy to work with recursive structures such as
syntax trees.”
[[}]]

● How GNU C lib handles backward compatibility: [[{01_PM.TODO]]
@[https://developers.redhat.com/blog/2019/08/01/how-the-gnu-c-library-handles-backward-compatibility/]
[[}]]

● Live Recorder 5  [[{01_PM.TODO]]
@[https://www.infoq.com/news/2019/12/undo-live-recorder/]
- Earlier in the year the Undo team released Live Recorder 5, the
  latest version of their “software flight recorder technology” for
  C/C++, Rust, and Go applications that enables the capture of all
  nondeterministic data within an application’s execution for
  debugging purposes. The captured recording allows the recreation of
  an application’s entire memory and the register state, which
  supports the replay of execution steps, backwards and forwards, via
  the UndoDB debugger. At the recent QCon San Francisco conference,
  InfoQ sat down with Dr Greg Law, co-founder and CTO at Undo, in order
  to learn more.
[[}]]

● GCC code instrumentation:  [[{gcc.101,qa]]
  https://gcc.gnu.org/onlinedocs/gcc/Instrumentation-Options.html
  -fsanitize=address
    Memory access instructions are instrumented to detect out-of-bounds and use-after-free bugs.
    See https://github.com/google/sanitizers/wiki/AddressSanitizer for more details.
    It cannot be combined with -fsanitize=thread or -fsanitize=hwaddress.

  Extracted from https://tip.golang.org/doc/go1.18
  go build command and related commands now support an -asan flag that
  enables interoperation with C (or C++) code compiled with the
  address sanitizer (C compiler option -fsanitize=address).
[[}]]

[[TODO}]]

